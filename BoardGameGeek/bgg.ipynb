{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b07267ee",
   "metadata": {},
   "source": [
    "[website](https://boardgamegeek.com/boardgame/224517/brass-birmingham/stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "565ab371",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import time\n",
    "import json\n",
    "import csv\n",
    "import os\n",
    "import logging\n",
    "import traceback\n",
    "import requests\n",
    "from tqdm import tqdm\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.common.exceptions import (\n",
    "    NoSuchElementException, StaleElementReferenceException, \n",
    "    TimeoutException, WebDriverException, InvalidSessionIdException\n",
    ")\n",
    "from webdriver_manager.chrome import ChromeDriverManager"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ebd0b4cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure logging\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format='%(asctime)s - %(levelname)s - %(message)s',\n",
    "    handlers=[\n",
    "        logging.FileHandler('scraper.log')\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "24c591af",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to extract players and play-time in SECTION 0\n",
    "\n",
    "def players_time(players, timing):\n",
    "    def extract_min_max(elements):\n",
    "        if elements:\n",
    "            text = elements[0].text.strip()\n",
    "            if '–' in text:\n",
    "                minimum = int(text.split('–')[0])\n",
    "                maximum = int(text.split('–')[1])\n",
    "            else:\n",
    "                minimum = maximum = int(text)\n",
    "        else:\n",
    "            minimum = maximum = None\n",
    "        return minimum, maximum\n",
    "\n",
    "    min_players, max_players = extract_min_max(players)\n",
    "    min_time, max_time = extract_min_max(timing)\n",
    "\n",
    "    return min_players, max_players, min_time, max_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4ca53764",
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to cleanly collect game credits in SECTION 1\n",
    "\n",
    "def get_credits(credits, index, new_line='\\n'):\n",
    "    try:\n",
    "        raw = credits[index].text\n",
    "        text = raw \n",
    "\n",
    "        result = text.split(new_line)\n",
    "        cleaned = [t.strip() for t in result if t.strip() and t.strip().upper() != 'N/A']\n",
    "        \n",
    "        return cleaned if cleaned else None\n",
    "    except (IndexError, ValueError, AttributeError):\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dcaafc56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# collect game stats in SECTION 2\n",
    "\n",
    "def get_stats(stats_elem, stats_index, sub_index, new_line='\\n'):\n",
    "    try:\n",
    "        stat_category = stats_elem[stats_index].text.split(new_line)\n",
    "        pre_stat = stat_category[sub_index].strip()\n",
    "        if ',' in pre_stat:\n",
    "            stat = int(pre_stat.replace(',',''))\n",
    "        elif ' / ' in pre_stat:\n",
    "            stat = float(pre_stat.split(' / ')[0])\n",
    "        else: stat = int(pre_stat) if pre_stat.isdigit() else pre_stat\n",
    "        return stat\n",
    "    except (IndexError, ValueError, AttributeError):\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d3739c23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to handle ratings in SECTION 3\n",
    "\n",
    "def get_rating(ratings, rating_index):\n",
    "    raw_rating = ratings[rating_index].text.strip()\n",
    "    if 'k' and '.' in raw_rating:\n",
    "        rating = int(raw_rating.replace('.', '').replace('k', '00'))\n",
    "    elif 'k' in raw_rating:\n",
    "        rating = int(raw_rating.replace('k', '000'))\n",
    "    else: rating = int(raw_rating)\n",
    "    return rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "604d6136",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to get current exchange rates so as to normalize all prices to USD\n",
    "def get_exchange_rates(base=\"USD\"):\n",
    "    url = f\"https://open.er-api.com/v6/latest/{base}\"\n",
    "    response = requests.get(url)\n",
    "    return response.json().get(\"rates\", {})\n",
    "\n",
    "# function to carry out the conversion \n",
    "def convert_to_usd(price, currency, exchange_rates):\n",
    "    if currency == \"USD\":\n",
    "        return price\n",
    "    rate = exchange_rates.get(currency)\n",
    "    if not rate:\n",
    "        return None \n",
    "    return round(price / rate, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7cdbf44a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to collect marketplace data \n",
    "def marketplace_crawler(store_elem):\n",
    "    shops_data = []\n",
    "    for row in store_elem:\n",
    "        store_name_elem = row.find_elements(By.XPATH, \".//div[contains(@class, 'summary-item-title')]\")\n",
    "        store_price_elem = row.find_elements(By.XPATH, \".//span[@itemprop='price'] | .//strong[contains(@class, 'ng-binding')]\")\n",
    "        currency_elem = row.find_elements(By.XPATH, './/span[@itemprop=\"priceCurrency\"]')\n",
    "\n",
    "        # time.sleep(20)\n",
    "        \n",
    "        for storage, pricing in zip(store_name_elem, store_price_elem):\n",
    "            store_raw = storage.text.strip()\n",
    "            price_raw = pricing.text.strip()\n",
    "\n",
    "            if not store_raw or not price_raw:\n",
    "                continue\n",
    "            \n",
    "            if '(' in store_raw:\n",
    "                store = store_raw.split(' ')[0]\n",
    "            else: store = store_raw\n",
    "            try:\n",
    "                if '$' in price_raw:\n",
    "                    price = float(price_raw.replace('$', '').strip())\n",
    "                else:\n",
    "                    price = float(price_raw)\n",
    "            except ValueError:\n",
    "                continue\n",
    "            currency = \"USD\"\n",
    "            for prefix in currency_elem:\n",
    "                if currency_elem:\n",
    "                    currency = prefix.get_attribute('content')\n",
    "                else:\n",
    "                    currency = 'USD'\n",
    "            \n",
    "            exchange_rates = get_exchange_rates(\"USD\")\n",
    "            price_usd = convert_to_usd(price, currency, exchange_rates)\n",
    "\n",
    "            shops_data.append({\n",
    "                'store': store,\n",
    "                'base_price': price,\n",
    "                'currency': currency,\n",
    "                'base_price_usd': price_usd\n",
    "            })\n",
    "\n",
    "    return shops_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c03ad0a2",
   "metadata": {},
   "source": [
    "Extraction Cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cd0c30f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Games Scraped: 0it [00:00, ?it/s]\n"
     ]
    }
   ],
   "source": [
    "driver = webdriver.Chrome(service=Service(ChromeDriverManager().install()))\n",
    "\n",
    "allboardgames = 0\n",
    "all_games_links = []\n",
    "\n",
    "destination = \"boardgamegeek.json\" \n",
    "if not os.path.exists(destination):\n",
    "    with open(destination, 'w') as f:\n",
    "        json.dump([], f)\n",
    "\n",
    "first_iteration = True\n",
    "row_number = 1001\n",
    "\n",
    "page_one = 11\n",
    "page_end = 16\n",
    "\n",
    "try:\n",
    "    logging.info(\"=\"*60)\n",
    "    logging.info(f\"Collecting boardgame links across {page_end - page_one} pages...\")\n",
    "    for page in range(page_one, page_end):\n",
    "        url = f\"https://boardgamegeek.com/browse/boardgame/page/{page}\"\n",
    "        driver.get(url)\n",
    "        time.sleep(10)  \n",
    "\n",
    "        try:\n",
    "            game_links_per_page = [link.get_attribute('href') for link in driver.find_elements(By.XPATH, '//a[@class=\"primary\"]')]\n",
    "            all_games_links.extend(game_links_per_page)\n",
    "        except (NoSuchElementException, StaleElementReferenceException) as e:\n",
    "                logging.warning(f\"Error on page {page}: {e}\")\n",
    "except (TimeoutException, WebDriverException, InvalidSessionIdException) as e:\n",
    "    logging.error(f\"Navigation error: {e}\")\n",
    "\n",
    "game_links = 'GoToGames.txt'\n",
    "with open(game_links, 'a', encoding='utf-8') as file:\n",
    "    for game_link in all_games_links:\n",
    "         file.write(game_link + '\\n')\n",
    "\n",
    "logging.info(f\"{len(all_games_links)} links found for this session and stored at {game_links}...\")\n",
    "\n",
    "with tqdm(total=len(all_games_links), desc=\"Games Scraped\") as pbar:\n",
    "\n",
    "    \n",
    "    for href in all_games_links:\n",
    "        \n",
    "        try:\n",
    "            start_time = time.time()\n",
    "            driver.get(href + '/credits') # plus /credits so we dont have to click on SeeFullCredits everytime in Section 1\n",
    "            # driver.get(href)\n",
    "            logging.info(f\"Accessing Webpage: {href}\")\n",
    "            time.sleep(10)\n",
    "\n",
    "            page_source = driver.page_source\n",
    "            # soup = BeautifulSoup(page_source, 'html.parser')\n",
    "\n",
    "        #Section 0\n",
    "        #xt/players and play-time\n",
    "            try:\n",
    "                players = driver.find_elements(By.XPATH, '//span[@ng-if=\"::geekitemctrl.geekitem.data.item.minplayers > 0 || geekitemctrl.geekitem.data.item.maxplayers > 0\"]')\n",
    "                timing = driver.find_elements(By.XPATH, '//span[@min=\"::geekitemctrl.geekitem.data.item.minplaytime\" and @max=\"::geekitemctrl.geekitem.data.item.maxplaytime\"]')\n",
    "                \n",
    "                description_elem = driver.find_elements(By.XPATH, '//span[@itemprop=\"description\"]')\n",
    "                description = description_elem[0].text.strip()\n",
    "                min_players, max_players, min_time, max_time = players_time(players, timing)\n",
    "\n",
    "                bg = {\n",
    "                    'row_id': row_number,\n",
    "                    'description': description,\n",
    "                    'player_counts': {\n",
    "                        'min_players': min_players,\n",
    "                        'max_players': max_players\n",
    "                    },\n",
    "                    'playtime': {\n",
    "                        'min_playtime': min_time,\n",
    "                        'max_playtime': max_time\n",
    "                    }\n",
    "                }\n",
    "            except Exception as e:\n",
    "                 logging.warning(f\"{e} during players & playtime extraction at {href}\")\n",
    "\n",
    "        #Section 1\n",
    "        #click on credits\n",
    "            # try:\n",
    "            #     SeeFullCredits = WebDriverWait(driver,10).until(\n",
    "            #         EC.element_to_be_clickable((By.XPATH, '//a[@ui-sref=\"geekitem.credits\"]'))\n",
    "            #     )\n",
    "            #     SeeFullCredits.click()\n",
    "            # except Exception as e:\n",
    "            #     logging.warning(f'Could not click Credits at {href}: {e}')\n",
    "\n",
    "        #wait for game_name and release year element\n",
    "            WebDriverWait(driver,10).until(\n",
    "            EC.visibility_of_element_located((By.XPATH, '//span[@ng-bind-html=\"creditsctrl.geekitem.data.item[info.keyname]|to_trusted\"]'))\n",
    "            )\n",
    "\n",
    "        #xt/game_name, release year\n",
    "            try:\n",
    "                spans = driver.find_elements(By.XPATH, '//span[@ng-bind-html=\"creditsctrl.geekitem.data.item[info.keyname]|to_trusted\"]')\n",
    "                credits = driver.find_elements(By.XPATH, '//div[@ng-if=\"info.datatype == \\'geekitem_linkdata\\'\"]')\n",
    "                minimum_age = driver.find_elements(By.XPATH, \"//span[@itemprop='suggestedMinAge']\")\n",
    "                age = int(minimum_age[0].text.strip()) if minimum_age[0].text.isdigit() else None\n",
    "\n",
    "                bg['boardgame'] = spans[0].text.strip()\n",
    "\n",
    "                game_name = spans[0].text.strip()\n",
    "                logging.info(f\"Now Scraping game {row_number}: {game_name} | URL: {href}\")\n",
    "\n",
    "                bg['minimum_age'] = age\n",
    "\n",
    "                bg['game_info'] = {\n",
    "                    'release_year' : int(spans[1].text.strip()) if spans[1].text.isdigit() else None,\n",
    "                    \"categories\": get_credits(credits, 10),\n",
    "                    \"mechanisms\": get_credits(credits, 11),\n",
    "                    \"family\": get_credits(credits, 12)\n",
    "                }\n",
    "\n",
    "        #xt/game-credits with the get_credits func.\n",
    "                bg['credits'] = {\n",
    "                    \"designers\": get_credits(credits, 0),\n",
    "                    \"solo_designer\": get_credits(credits, 1),\n",
    "                    \"artists\": get_credits(credits, 2),\n",
    "                    \"publishers\": get_credits(credits, 3),\n",
    "                    \"developer\": get_credits(credits, 4),\n",
    "                    \"graphic_designer\": get_credits(credits, 5),\n",
    "                    \"sculptor\": get_credits(credits, 6),\n",
    "                    \"editor\": get_credits(credits, 7),\n",
    "                    \"writer\": get_credits(credits, 8),\n",
    "                    \"insert_designer\": get_credits(credits, 9)\n",
    "                }\n",
    "            except Exception as e:\n",
    "                logging.warning(f\"{e} in credits section of {driver.current_url}\")\n",
    "        \n",
    "        #Section 2\n",
    "        #click on stats section\n",
    "            SeeGameStats = WebDriverWait(driver,10).until(\n",
    "            EC.element_to_be_clickable((By.XPATH, '//a[@ui-sref=\"geekitem.stats({})\"]'))\n",
    "            )\n",
    "            SeeGameStats.click()\n",
    "\n",
    "        #wait until stats appear\n",
    "            WebDriverWait(driver,10).until(\n",
    "                EC.visibility_of_element_located((By.XPATH, '//div[@class=\"row game-stats\"]'))\n",
    "            )\n",
    "\n",
    "            try:\n",
    "        #xt/relevant stats with get_stats func.\n",
    "                stats_elem = driver.find_elements(By.XPATH, '//ul[@class=\"outline fs-responsive-sm outline-border-col-xs\"]')\n",
    "\n",
    "        #game stats\n",
    "                bg['game_stats'] = {\n",
    "                    \"average_rating\": get_stats(stats_elem, 0, 1),\n",
    "                    \"num_of_ratings\": get_stats(stats_elem, 0, 3),\n",
    "                    \"std_deviation\": get_stats(stats_elem, 0, 5),\n",
    "                    \"weight\": get_stats(stats_elem, 0, 7),\n",
    "                    \"comments\": get_stats(stats_elem, 0, 9),\n",
    "                    \"fans\": get_stats(stats_elem, 0, 11),\n",
    "                    \"page_views\": get_stats(stats_elem, 0, 13)\n",
    "                }\n",
    "            except Exception as e:\n",
    "                logging.warning(f\"{e} in game stats of {driver.current_url}\")\n",
    "\n",
    "        #ranks stats\n",
    "            bg['ranks']={}\n",
    "            try:\n",
    "                rank_labels = driver.find_elements(By.XPATH, '//span[@class=\"rank-title ng-binding\"]')\n",
    "                rank_values = driver.find_elements(By.XPATH, '//a[@class=\"rank-value ng-binding ng-scope\"]')\n",
    "\n",
    "                for label, value in zip(rank_labels, rank_values):\n",
    "                    bg['ranks'][label.text.strip().lower()] = int(value.text.replace(\",\",\"\").strip())\n",
    "\n",
    "            except Exception as e:\n",
    "                logging.warning(f\"{e} in rank stats of {href}\")\n",
    "\n",
    "        #play stats\n",
    "            try:\n",
    "                bg['play_stats'] = {\n",
    "                    \"all_time_plays\": get_stats(stats_elem, 2, 1),\n",
    "                    \"this_month_plays\": get_stats(stats_elem, 2, 3)\n",
    "                }\n",
    "            except Exception as e:\n",
    "                logging.warning(f\"{e} in play stats of {driver.current_url}\")\n",
    "\n",
    "        #collecton stats\n",
    "            try:\n",
    "                bg['collection_stats'] = {\n",
    "                    \"own\": get_stats(stats_elem, 3, 1),\n",
    "                    \"previously_owned\": get_stats(stats_elem, 3, 3),\n",
    "                    \"for_trade\": get_stats(stats_elem, 3, 5),\n",
    "                    \"want_in_trade\": get_stats(stats_elem, 3, 8),\n",
    "                    \"wishlist\": get_stats(stats_elem, 3, 11)\n",
    "                }\n",
    "            except Exception as e:\n",
    "                logging.warning(f\"{e} in collection stats of {driver.current_url}\")\n",
    "\n",
    "        #Section 3\n",
    "        #wait until ratings appear\n",
    "            WebDriverWait(driver, 10).until(\n",
    "                lambda d: len(d.find_elements(By.XPATH, \"//*[name()='text']\")) >= 20\n",
    "            )\n",
    "            try:\n",
    "                ratings = driver.find_elements(By.XPATH, \"//*[name()='text']\") #workaround xpath for html that include namespaces like SVG in this case\n",
    "            \n",
    "            #xt/ratings with the get_rating function    \n",
    "                bg['ratings'] = {\n",
    "                    f\"rated_{i}\": get_rating(ratings, 9 + i)\n",
    "                    for i in range(1, 11)\n",
    "                }\n",
    "            except Exception as e:\n",
    "                logging.warning(f\"{e} in scraping ratings of {driver.current_url}\")\n",
    "\n",
    "            \n",
    "        #Section 4 \n",
    "        #Click on Shoppings Tab\n",
    "            try:\n",
    "                ShopListings = WebDriverWait(driver,10).until(\n",
    "                    EC.element_to_be_clickable((By.XPATH, '//a[@ui-sref=\"geekitem.marketplace.stores({})\"]'))\n",
    "                    )\n",
    "                ShopListings.click()\n",
    "\n",
    "        # wait until all store items become visible \n",
    "                try:\n",
    "                    WebDriverWait(driver, 15).until(\n",
    "                        EC.visibility_of_element_located((By.XPATH, \"//li[contains(@class, 'summary-sale-item')]\"))\n",
    "                    )\n",
    "                except TimeoutException:\n",
    "                    WebDriverWait(driver, 5).until(\n",
    "                        EC.visibility_of_element_located((By.XPATH,  \"//stores-items-module\"))\n",
    "                    )\n",
    "\n",
    "        #collect data with the marketplace_crawler function\n",
    "                store_elem = driver.find_elements(By.XPATH, \"//li[contains(@class, 'summary-sale-item')]\")\n",
    "                \n",
    "                # bg['marketplace'] = shops_data\n",
    "                marketplace_data = marketplace_crawler(store_elem)\n",
    "                bg['marketplace'] = marketplace_data \n",
    "            except Exception as e:\n",
    "                logging.warning(f\"{e} in scraping shop listings at {driver.current_url}\")\n",
    "                \n",
    "            bg['link_to_game']=href\n",
    "\n",
    "            end_time = time.time()\n",
    "            duration = end_time - start_time\n",
    "\n",
    "            logging.info(f\"Scraping completed for {game_name} in {duration:.2f} seconds.\")\n",
    "        \n",
    "            with open(destination, 'r', encoding='utf-8') as f:\n",
    "                    content = f.read()\n",
    "                    data = json.loads(content) if content.strip() else []\n",
    "            data.append(bg)\n",
    "            \n",
    "            with open(destination, \"w\", encoding=\"utf-8\") as f:\n",
    "                json.dump(data, f, indent=4, ensure_ascii=False)\n",
    "\n",
    "            logging.info(f\"Records dumped in json file: {destination}\")\n",
    "    \n",
    "        except Exception as e:\n",
    "            logging.error(f\"Error scraping boardgame, {bg.get('name')} at {url} - {type(e).__name__}: {e}\")\n",
    "            logging.error(traceback.format_exc())\n",
    "        logging.info(\"=\"*75)\n",
    "        row_number +=1\n",
    "        allboardgames+=1\n",
    "        pbar.update(1)\n",
    "\n",
    "            \n",
    "driver.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e347d5ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_destination = \"boardgame-geek-dataset.csv\"\n",
    "\n",
    "with open(destination, \"r\", encoding=\"utf-8\") as f:\n",
    "    data = json.load(f)  \n",
    "\n",
    "# Flatten marketplace (special handling)\n",
    "def flatten_marketplace(record):\n",
    "    flat_market = {}\n",
    "    for store in record.get(\"marketplace\", []):\n",
    "        store_name = store[\"store\"].lower().replace(\" \", \"_\")\n",
    "        currency = store[\"currency\"].lower()\n",
    "        \n",
    "        price_col = f\"{store_name}_price_{currency}\"\n",
    "        flat_market[price_col] = store.get(\"base_price\")\n",
    "\n",
    "        if currency != \"usd\":\n",
    "            usd_col = f\"{store_name}_price_usd\"\n",
    "            flat_market[usd_col] = store.get(\"base_price_usd\")\n",
    "\n",
    "    return flat_market\n",
    "\n",
    "# Recursive flattener for nested dicts\n",
    "def flatten_dict(d, parent_key=\"\", sep=\"_\"):\n",
    "    items = []\n",
    "    for k, v in d.items():\n",
    "        new_key = f\"{parent_key}{sep}{k}\" if parent_key else k\n",
    "        if isinstance(v, dict):\n",
    "            items.extend(flatten_dict(v, new_key, sep=sep).items())\n",
    "        elif isinstance(v, list) and all(isinstance(x, dict) for x in v):\n",
    "            continue\n",
    "        elif isinstance(v, list):\n",
    "            items.append((new_key, \";\".join(map(str, v))))\n",
    "        else:\n",
    "            items.append((new_key, v))\n",
    "    return dict(items)\n",
    "\n",
    "# Full record flattener\n",
    "def flatten_record(record):\n",
    "    flat = flatten_dict(record)\n",
    "    flat.update(flatten_marketplace(record))\n",
    "    flat.pop(\"marketplace\", None)\n",
    "\n",
    "    return flat\n",
    "\n",
    "flat_records = [flatten_record(rec) for rec in data]\n",
    "\n",
    "df = pd.DataFrame(flat_records)\n",
    "df.to_csv(final_destination, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73c6dd38",
   "metadata": {},
   "source": [
    "Sandbox"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1eb65934",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Games Scraped: 100%|██████████| 100/100 [1:18:34<00:00, 47.14s/it]\n"
     ]
    }
   ],
   "source": [
    "class UserAgentRotator:\n",
    "    def __init__(self):\n",
    "        self.user_agents = [\n",
    "            # Chrome Windows\n",
    "            \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36\",\n",
    "            \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/119.0.0.0 Safari/537.36\",\n",
    "            \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/118.0.0.0 Safari/537.36\",\n",
    "            # Chrome Mac\n",
    "            \"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36\",\n",
    "            \"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/119.0.0.0 Safari/537.36\",\n",
    "            # Firefox Windows\n",
    "            \"Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:121.0) Gecko/20100101 Firefox/121.0\",\n",
    "            \"Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:120.0) Gecko/20100101 Firefox/120.0\",\n",
    "            # Firefox Mac\n",
    "            \"Mozilla/5.0 (Macintosh; Intel Mac OS X 10.15; rv:121.0) Gecko/20100101 Firefox/121.0\",\n",
    "            # Safari Mac\n",
    "            \"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/605.1.15 (KHTML, like Gecko) Version/17.1 Safari/605.1.15\",\n",
    "            # Edge Windows\n",
    "            \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36 Edg/120.0.0.0\",\n",
    "            # Chrome Linux\n",
    "            \"Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36\",\n",
    "        ]\n",
    "        \n",
    "        self.resolutions = [\n",
    "            (1920, 1080), (1366, 768), (1536, 864), (1440, 900),\n",
    "            (1280, 720), (1600, 900), (2560, 1440), (1920, 1200)\n",
    "        ]\n",
    "\n",
    "    def get_random_user_agent(self):\n",
    "        return random.choice(self.user_agents)\n",
    "    \n",
    "    def get_random_resolution(self):\n",
    "        return random.choice(self.resolutions)\n",
    "\n",
    "    def create_driver_with_rotation(self, headless=False):\n",
    "        \"\"\"Create a new driver with randomized user agent and anti-detection measures\"\"\"\n",
    "        options = Options()\n",
    "        \n",
    "        # Random user agent\n",
    "        user_agent = self.get_random_user_agent()\n",
    "        options.add_argument(f\"--user-agent={user_agent}\")\n",
    "        \n",
    "        # Anti-detection measures\n",
    "        options.add_argument(\"--disable-blink-features=AutomationControlled\")\n",
    "        options.add_experimental_option(\"excludeSwitches\", [\"enable-automation\"])\n",
    "        options.add_experimental_option('useAutomationExtension', False)\n",
    "        options.add_argument(\"--disable-web-security\")\n",
    "        options.add_argument(\"--allow-running-insecure-content\")\n",
    "        options.add_argument(\"--disable-extensions\")\n",
    "        options.add_argument(\"--disable-plugins\")\n",
    "        options.add_argument(\"--no-sandbox\")\n",
    "        options.add_argument(\"--disable-dev-shm-usage\")\n",
    "        \n",
    "        # Random window size\n",
    "        width, height = self.get_random_resolution()\n",
    "        options.add_argument(f\"--window-size={width},{height}\")\n",
    "        \n",
    "        if headless:\n",
    "            options.add_argument(\"--headless\")\n",
    "        \n",
    "        # Create driver\n",
    "        driver = webdriver.Chrome(service=Service(ChromeDriverManager().install()), options=options)\n",
    "        \n",
    "        # Execute script to remove webdriver property\n",
    "        driver.execute_script(\"Object.defineProperty(navigator, 'webdriver', {get: () => undefined})\")\n",
    "        \n",
    "        logging.info(f\"Created new driver with User-Agent: {user_agent[:60]}...\")\n",
    "        return driver\n",
    "\n",
    "# Main scraper with rotation integration  \n",
    "def scrape_boardgames_with_rotation():\n",
    "    rotator = UserAgentRotator()\n",
    "    driver = None\n",
    "    \n",
    "    # Your existing variables\n",
    "    allboardgames = 0\n",
    "    all_games_links = []\n",
    "    destination = \"boardgamegeek.json\"\n",
    "    \n",
    "    if not os.path.exists(destination):\n",
    "        with open(destination, 'w') as f:\n",
    "            json.dump([], f)\n",
    "\n",
    "    row_number = 1001\n",
    "    page_one = 11\n",
    "    page_end = 12\n",
    "    \n",
    "    # Rotation settings\n",
    "    ROTATION_FREQUENCY = 15  # Rotate more frequently \n",
    "    MAX_RETRIES = 2  # Reduce retries to avoid getting stuck\n",
    "    \n",
    "    try:\n",
    "        # Initial driver creation\n",
    "        driver = rotator.create_driver_with_rotation(headless=False)\n",
    "        \n",
    "        # Step 1: Collect game links (your existing logic)\n",
    "        logging.info(\"=\"*60)\n",
    "        logging.info(f\"Collecting boardgame links across {page_end - page_one} pages...\")\n",
    "        \n",
    "        for page in range(page_one, page_end):\n",
    "            url = f\"https://boardgamegeek.com/browse/boardgame/page/{page}\"\n",
    "            \n",
    "            # Retry logic for page loading\n",
    "            for attempt in range(MAX_RETRIES):\n",
    "                try:\n",
    "                    driver.get(url)\n",
    "                    time.sleep(random.uniform(8, 15))  # Random delay\n",
    "                    \n",
    "                    game_links_per_page = [\n",
    "                        link.get_attribute('href') \n",
    "                        for link in driver.find_elements(By.XPATH, '//a[@class=\"primary\"]')\n",
    "                    ]\n",
    "                    all_games_links.extend(game_links_per_page)\n",
    "                    break\n",
    "                    \n",
    "                except (TimeoutException, WebDriverException, InvalidSessionIdException) as e:\n",
    "                    logging.warning(f\"Attempt {attempt + 1} failed for page {page}: {e}\")\n",
    "                    if attempt == MAX_RETRIES - 1:\n",
    "                        # Rotate user agent on final failure\n",
    "                        logging.info(\"Max retries reached, rotating user agent...\")\n",
    "                        try:\n",
    "                            driver.quit()\n",
    "                        except:\n",
    "                            pass\n",
    "                        driver = rotator.create_driver_with_rotation(headless=False)\n",
    "                        time.sleep(random.uniform(10, 20))\n",
    "                    else:\n",
    "                        time.sleep(random.uniform(15, 30))\n",
    "                        \n",
    "        # Save links to file\n",
    "        game_links = 'GoToGames.txt'\n",
    "        with open(game_links, 'a', encoding='utf-8') as file:\n",
    "            for game_link in all_games_links:\n",
    "                file.write(game_link + '\\n')\n",
    "\n",
    "        logging.info(f\"{len(all_games_links)} links found for this session and stored at {game_links}...\")\n",
    "\n",
    "        # Step 2: Scrape individual games with rotation\n",
    "        with tqdm(total=len(all_games_links), desc=\"Games Scraped\") as pbar:\n",
    "            \n",
    "            for idx, href in enumerate(all_games_links):\n",
    "                \n",
    "                # Rotate user agent every ROTATION_FREQUENCY games\n",
    "                if idx > 0 and idx % ROTATION_FREQUENCY == 0:\n",
    "                    logging.info(f\"Rotating user agent at game {idx + 1} (row {row_number})\")\n",
    "                    try:\n",
    "                        driver.quit()\n",
    "                    except:\n",
    "                        pass\n",
    "                    driver = rotator.create_driver_with_rotation(headless=False)\n",
    "                    time.sleep(random.uniform(15, 25))  # Longer delay after rotation\n",
    "                \n",
    "                # Main scraping logic with retry mechanism\n",
    "                game_scraped = False\n",
    "                retry_count = 0\n",
    "                \n",
    "                while not game_scraped and retry_count < MAX_RETRIES:\n",
    "                    try:\n",
    "                        # Check if driver is still alive\n",
    "                        try:\n",
    "                            driver.current_url\n",
    "                        except (InvalidSessionIdException, WebDriverException):\n",
    "                            logging.info(\"Driver session lost, creating new one...\")\n",
    "                            driver = rotator.create_driver_with_rotation(headless=False)\n",
    "                            time.sleep(random.uniform(10, 15))\n",
    "                        \n",
    "                        start_time = time.time()\n",
    "                        \n",
    "                        # Navigate to credits page\n",
    "                        driver.get(href + '/credits')\n",
    "                        logging.info(f\"Accessing Webpage: {href}\")\n",
    "                        time.sleep(random.uniform(8, 15))\n",
    "\n",
    "                        # Initialize bg dict properly\n",
    "                        bg = {}\n",
    "\n",
    "                        # Section 0: Basic game info\n",
    "                        try:\n",
    "                            players = driver.find_elements(By.XPATH, '//span[@ng-if=\"::geekitemctrl.geekitem.data.item.minplayers > 0 || geekitemctrl.geekitem.data.item.maxplayers > 0\"]')\n",
    "                            timing = driver.find_elements(By.XPATH, '//span[@min=\"::geekitemctrl.geekitem.data.item.minplaytime\" and @max=\"::geekitemctrl.geekitem.data.item.maxplaytime\"]')\n",
    "                            \n",
    "                            description_elem = driver.find_elements(By.XPATH, '//span[@itemprop=\"description\"]')\n",
    "                            description = description_elem[0].text.strip() if description_elem else \"No description\"\n",
    "                            min_players, max_players, min_time, max_time = players_time(players, timing)\n",
    "\n",
    "                            bg.update({\n",
    "                                'row_id': row_number,\n",
    "                                'description': description,\n",
    "                                'player_counts': {\n",
    "                                    'min_players': min_players,\n",
    "                                    'max_players': max_players\n",
    "                                },\n",
    "                                'playtime': {\n",
    "                                    'min_playtime': min_time,\n",
    "                                    'max_playtime': max_time\n",
    "                                }\n",
    "                            })\n",
    "                        except Exception as e:\n",
    "                            logging.warning(f\"{e} during players & playtime extraction at {href}\")\n",
    "\n",
    "                        # Section 1: Game details and credits\n",
    "                        WebDriverWait(driver, 10).until(\n",
    "                            EC.visibility_of_element_located((By.XPATH, '//span[@ng-bind-html=\"creditsctrl.geekitem.data.item[info.keyname]|to_trusted\"]'))\n",
    "                        )\n",
    "\n",
    "                        try:\n",
    "                            spans = driver.find_elements(By.XPATH, '//span[@ng-bind-html=\"creditsctrl.geekitem.data.item[info.keyname]|to_trusted\"]')\n",
    "                            credits = driver.find_elements(By.XPATH, '//div[@ng-if=\"info.datatype == \\'geekitem_linkdata\\'\"]')\n",
    "                            minimum_age = driver.find_elements(By.XPATH, \"//span[@itemprop='suggestedMinAge']\")\n",
    "                            age = int(minimum_age[0].text.strip()) if minimum_age and minimum_age[0].text.isdigit() else None\n",
    "\n",
    "                            game_name = spans[0].text.strip() if spans else f\"Unknown Game {row_number}\"\n",
    "                            bg['boardgame'] = game_name\n",
    "                            logging.info(f\"Now Scraping game {row_number}: {game_name} | URL: {href}\")\n",
    "\n",
    "                            bg['minimum_age'] = age\n",
    "                            bg['game_info'] = {\n",
    "                                'release_year': int(spans[1].text.strip()) if len(spans) > 1 and spans[1].text.isdigit() else None,\n",
    "                                \"categories\": get_credits(credits, 10),\n",
    "                                \"mechanisms\": get_credits(credits, 11), \n",
    "                                \"family\": get_credits(credits, 12)\n",
    "                            }\n",
    "\n",
    "                        #xt/game-credits with the get_credits func.\n",
    "                            bg['credits'] = {\n",
    "                                \"designers\": get_credits(credits, 0),\n",
    "                                \"solo_designer\": get_credits(credits, 1),\n",
    "                                \"artists\": get_credits(credits, 2),\n",
    "                                \"publishers\": get_credits(credits, 3),\n",
    "                                \"developer\": get_credits(credits, 4),\n",
    "                                \"graphic_designer\": get_credits(credits, 5),\n",
    "                                \"sculptor\": get_credits(credits, 6),\n",
    "                                \"editor\": get_credits(credits, 7),\n",
    "                                \"writer\": get_credits(credits, 8),\n",
    "                                \"insert_designer\": get_credits(credits, 9)\n",
    "                            }\n",
    "                        except Exception as e:\n",
    "                            logging.warning(f\"{e} in credits section of {driver.current_url}\")\n",
    "                        \n",
    "                        # Section 2: Stats (simplified for now)\n",
    "                        try:\n",
    "                        #click on stats section\n",
    "                            SeeGameStats = WebDriverWait(driver, 15).until(\n",
    "                                EC.element_to_be_clickable((By.XPATH, '//a[@ui-sref=\"geekitem.stats({})\"]'))\n",
    "                            )\n",
    "                            SeeGameStats.click()\n",
    "\n",
    "                        #wait until stats appear\n",
    "                            WebDriverWait(driver, 10).until(\n",
    "                                EC.visibility_of_element_located((By.XPATH, '//div[@class=\"row game-stats\"]'))\n",
    "                            )\n",
    "\n",
    "                        # extract relevant stats with get_stats func.\n",
    "                            stats_elem = driver.find_elements(By.XPATH, '//ul[@class=\"outline fs-responsive-sm outline-border-col-xs\"]')\n",
    "\n",
    "                        #game stats\n",
    "                            bg['game_stats'] = {\n",
    "                                \"average_rating\": get_stats(stats_elem, 0, 1),\n",
    "                                \"num_of_ratings\": get_stats(stats_elem, 0, 3),\n",
    "                                \"std_deviation\": get_stats(stats_elem, 0, 5),\n",
    "                                \"weight\": get_stats(stats_elem, 0, 7),\n",
    "                                \"comments\": get_stats(stats_elem, 0, 9),\n",
    "                                \"fans\": get_stats(stats_elem, 0, 11),\n",
    "                                \"page_views\": get_stats(stats_elem, 0, 13)\n",
    "                            }\n",
    "                        except Exception as e:\n",
    "                            logging.warning(f\"{e} in game stats of {driver.current_url}\")\n",
    "\n",
    "                    #ranks stats\n",
    "                        bg['ranks']={}\n",
    "                        try:\n",
    "                            rank_labels = driver.find_elements(By.XPATH, '//span[@class=\"rank-title ng-binding\"]')\n",
    "                            rank_values = driver.find_elements(By.XPATH, '//a[@class=\"rank-value ng-binding ng-scope\"]')\n",
    "\n",
    "                            for label, value in zip(rank_labels, rank_values):\n",
    "                                bg['ranks'][label.text.strip().lower()] = int(value.text.replace(\",\",\"\").strip())\n",
    "\n",
    "                        except Exception as e:\n",
    "                            logging.warning(f\"{e} in rank stats of {href}\")\n",
    "\n",
    "                    #play stats\n",
    "                        try:\n",
    "                            bg['play_stats'] = {\n",
    "                                \"all_time_plays\": get_stats(stats_elem, 2, 1),\n",
    "                                \"this_month_plays\": get_stats(stats_elem, 2, 3)\n",
    "                            }\n",
    "                        except Exception as e:\n",
    "                            logging.warning(f\"{e} in play stats of {driver.current_url}\")\n",
    "\n",
    "                    #collecton stats\n",
    "                        try:\n",
    "                            bg['collection_stats'] = {\n",
    "                                \"own\": get_stats(stats_elem, 3, 1),\n",
    "                                \"previously_owned\": get_stats(stats_elem, 3, 3),\n",
    "                                \"for_trade\": get_stats(stats_elem, 3, 5),\n",
    "                                \"want_in_trade\": get_stats(stats_elem, 3, 8),\n",
    "                                \"wishlist\": get_stats(stats_elem, 3, 11)\n",
    "                            }\n",
    "                        except Exception as e:\n",
    "                            logging.warning(f\"{e} in collection stats of {driver.current_url}\")\n",
    "                        \n",
    "                    #Section 3\n",
    "                    #wait until ratings appear\n",
    "                        WebDriverWait(driver, 10).until(\n",
    "                            lambda d: len(d.find_elements(By.XPATH, \"//*[name()='text']\")) >= 20\n",
    "                        )\n",
    "                        try:\n",
    "                            ratings = driver.find_elements(By.XPATH, \"//*[name()='text']\") #workaround xpath for html that include namespaces like SVG in this case\n",
    "                        \n",
    "                        #xt/ratings with the get_rating function    \n",
    "                            bg['ratings'] = {\n",
    "                                f\"rated_{i}\": get_rating(ratings, 9 + i)\n",
    "                                for i in range(1, 11)\n",
    "                            }\n",
    "                        except Exception as e:\n",
    "                            logging.warning(f\"{e} in scraping ratings of {driver.current_url}\")\n",
    "\n",
    "                        \n",
    "                    #Section 4 \n",
    "                    #Click on Shoppings Tab\n",
    "                        try:\n",
    "                            ShopListings = WebDriverWait(driver,10).until(\n",
    "                                EC.element_to_be_clickable((By.XPATH, '//a[@ui-sref=\"geekitem.marketplace.stores({})\"]'))\n",
    "                                )\n",
    "                            ShopListings.click()\n",
    "\n",
    "                    # wait until all store items become visible \n",
    "                            try:\n",
    "                                WebDriverWait(driver, 15).until(\n",
    "                                    EC.visibility_of_element_located((By.XPATH, \"//li[contains(@class, 'summary-sale-item')]\"))\n",
    "                                )\n",
    "                            except TimeoutException:\n",
    "                                WebDriverWait(driver, 5).until(\n",
    "                                    EC.visibility_of_element_located((By.XPATH,  \"//stores-items-module\"))\n",
    "                                )\n",
    "\n",
    "                    #collect data with the marketplace_crawler function\n",
    "                            store_elem = driver.find_elements(By.XPATH, \"//li[contains(@class, 'summary-sale-item')]\")\n",
    "                            \n",
    "                            # bg['marketplace'] = shops_data\n",
    "                            marketplace_data = marketplace_crawler(store_elem)\n",
    "                            bg['marketplace'] = marketplace_data \n",
    "                        except Exception as e:\n",
    "                            logging.warning(f\"{e} in scraping shop listings at {driver.current_url}\")\n",
    "                            \n",
    "                        bg['link_to_game']=href\n",
    "\n",
    "                        end_time = time.time()\n",
    "                        duration = end_time - start_time\n",
    "                        game_name = bg.get('boardgame', 'Unknown Game')\n",
    "                        logging.info(f\"Scraping completed for {game_name} in {duration:.2f} seconds.\")\n",
    "                    \n",
    "                        # Save to JSON with better error handling\n",
    "                        try:\n",
    "                            # Read existing data\n",
    "                            if os.path.exists(destination) and os.path.getsize(destination) > 0:\n",
    "                                with open(destination, 'r', encoding='utf-8') as f:\n",
    "                                    data = json.load(f)\n",
    "                            else:\n",
    "                                data = []\n",
    "                            \n",
    "                            # Append new data\n",
    "                            data.append(bg)\n",
    "                            \n",
    "                            # Write back to file\n",
    "                            with open(destination, \"w\", encoding=\"utf-8\") as f:\n",
    "                                json.dump(data, f, indent=4, ensure_ascii=False)\n",
    "\n",
    "                            logging.info(f\"Successfully saved game {row_number} to {destination}\")\n",
    "                            \n",
    "                        except Exception as json_error:\n",
    "                            logging.error(f\"Failed to save to JSON: {json_error}\")\n",
    "                            # Try to save as backup\n",
    "                            backup_file = f\"backup_game_{row_number}.json\"\n",
    "                            with open(backup_file, \"w\", encoding=\"utf-8\") as f:\n",
    "                                json.dump(bg, f, indent=4, ensure_ascii=False)\n",
    "                            logging.info(f\"Saved backup to {backup_file}\")\n",
    "                        \n",
    "                        # Success - exit retry loop\n",
    "                        game_scraped = True\n",
    "                        \n",
    "                    except Exception as e:\n",
    "                        retry_count += 1\n",
    "                        logging.error(f\"Attempt {retry_count} failed for {href}: {type(e).__name__}: {e}\")\n",
    "                        \n",
    "                        if retry_count < MAX_RETRIES:\n",
    "                            # Rotate user agent on error\n",
    "                            logging.info(\"Error encountered, rotating user agent...\")\n",
    "                            try:\n",
    "                                driver.quit()\n",
    "                            except:\n",
    "                                pass\n",
    "                            driver = rotator.create_driver_with_rotation(headless=False)\n",
    "                            time.sleep(random.uniform(20, 35))\n",
    "                        else:\n",
    "                            logging.error(f\"Max retries reached for {href}\")\n",
    "                            logging.error(traceback.format_exc())\n",
    "                \n",
    "                logging.info(\"=\"*75)\n",
    "                row_number += 1\n",
    "                allboardgames += 1\n",
    "                pbar.update(1)\n",
    "                \n",
    "                # Random delay between games\n",
    "                time.sleep(random.uniform(5, 12))\n",
    "                \n",
    "    finally:\n",
    "        if driver:\n",
    "            try:\n",
    "                driver.quit()\n",
    "            except:\n",
    "                pass\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    scrape_boardgames_with_rotation()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
