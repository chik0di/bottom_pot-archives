{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Website](https://nigeriapropertycentre.com/for-sale/houses/showtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.support.ui import Select\n",
    "import pandas as pd\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Response [200]>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# url = \"https://nigeriapropertycentre.com/for-sale/houses/showtype?page=1\"\n",
    "\n",
    "url = \"https://nigeriapropertycentre.com/for-sale/houses/detached-duplexes/lagos/lekki/ikota/2559353-five-bedroom-fully-detached-duplex\"\n",
    "response = requests.get(url)\n",
    "soup = BeautifulSoup(response.text, 'html')\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraped page 1 of 2.\n",
      "Scraped page 2 of 2.\n"
     ]
    }
   ],
   "source": [
    "properties = []\n",
    "page_count = 0\n",
    "max_pages = 1\n",
    "\n",
    "path = \"C:/Users/HP/Downloads/chromedriver-win64/chromedriver.exe\"\n",
    "url = \"https://nigeriapropertycentre.com/for-sale/houses/showtype\"\n",
    "\n",
    "service = Service(path)\n",
    "driver = webdriver.Chrome(service=service)\n",
    "\n",
    "driver.get(url)\n",
    "property_links = [link.get_attribute('href') for link in driver.find_elements(By.XPATH, '//a[@itemprop=\"url\"]')]\n",
    "\n",
    "while page_count<=max_pages:\n",
    "\n",
    "    time.sleep(3)\n",
    "\n",
    "    page_source = driver.page_source\n",
    "    soup = BeautifulSoup(page_source, 'html')\n",
    "\n",
    "    for link_url in property_links:\n",
    "        driver.get(link_url)\n",
    "        time.sleep(3)\n",
    "\n",
    "        rows = soup.find_all('table', class_= 'table table-bordered table-striped')        \n",
    "        \n",
    "        for row in rows:\n",
    "            line = row.find_all('td')\n",
    "            fields = [h.text.strip() for h in line]\n",
    "            \n",
    "            table = {\n",
    "                field.split(\":\")[0].strip(): field.split(\":\")[1].strip() \n",
    "                for field in fields if \":\" in field # and len(field.split(\":\")) > 1\n",
    "                }\n",
    "\n",
    "            figure = soup.find_all('span', class_='price')[1]\n",
    "            price = float(figure.attrs['content'])\n",
    "            table['Price'] = price\n",
    "\n",
    "            address = soup.find('div', class_='col-sm-8 f15 property-details')\n",
    "            location = address.text.strip().split(',')[-2:]\n",
    "            city = location[0].strip()\n",
    "            state = location[1].strip()\n",
    "            table['District'] = city \n",
    "            table['State'] = state\n",
    "\n",
    "            properties.append(table)\n",
    "\n",
    "            # back = driver.find_element(By.XPATH, '//a[@class=\"underline\"]')\n",
    "            # back.click()\n",
    "        driver.back()\n",
    "        time.sleep(3) \n",
    "\n",
    "    page_count +=1\n",
    "    print(f'Scraped page {page_count} of {max_pages}.')\n",
    "\n",
    "    try:\n",
    "        next_icon = driver.find_element(By.XPATH, \"//a[@rel='next']\")\n",
    "        next_icon.click()\n",
    "    except:\n",
    "        print(\"No more pages to scrape\")\n",
    "        break\n",
    "\n",
    "# driver.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "properties"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
